# memory/__init__.py
"""
Syst√®me de M√©moire Complet de l'AGI √âvolutive
Int√®gre m√©moire de travail, √©pisodique, s√©mantique, proc√©durale et consolidation
"""

import numpy as np
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import heapq
import json
import hashlib
from .retrieval import MemoryRetrieval

class MemoryType(Enum):
    """Types de m√©moire dans le syst√®me"""
    SENSORY = "sensorielle"
    WORKING = "travail"
    EPISODIC = "√©pisodique"
    SEMANTIC = "s√©mantique"
    PROCEDURAL = "proc√©durale"
    AUTOBIOGRAPHICAL = "autobiographique"

class MemoryConsolidationState(Enum):
    """√âtats de consolidation m√©moire"""
    LABILE = "labile"          # M√©moire fragile
    CONSOLIDATING = "consolidation" # En cours de consolidation
    STABLE = "stable"          # M√©moire stable
    RECONSOLIDATING = "reconsolidation" # En reconsolidation

@dataclass
class MemoryTrace:
    """Trace mn√©sique individuelle"""
    id: str
    content: Any
    memory_type: MemoryType
    strength: float  # 0.0 √† 1.0
    accessibility: float  # Facilit√© d'acc√®s
    valence: float  # Charge √©motionnelle
    timestamp: float
    context: Dict[str, Any]
    associations: List[str]  # IDs des m√©moires associ√©es
    consolidation_state: MemoryConsolidationState
    last_accessed: float
    access_count: int

@dataclass
class MemoryRetrieval:
    """R√©sultat d'une r√©cup√©ration m√©moire"""
    memory_traces: List[MemoryTrace]
    confidence: float
    retrieval_time: float
    context_match: float
    emotional_coherence: float

class MemorySystem:
    """
    Syst√®me de m√©moire complet inspir√© de l'architecture cognitive humaine
    Impl√©mente les syst√®mes de m√©moire multiples avec consolidation
    """
    
    def __init__(self, cognitive_architecture=None):
        self.cognitive_architecture = cognitive_architecture
        self.creation_time = time.time()

        try:
            self.retrieval = MemoryRetrieval()
        except Exception:
            self.retrieval = None

        # ‚Äî‚Äî‚Äî LIAISONS INTER-MODULES ‚Äî‚Äî‚Äî
        if self.cognitive_architecture is not None:
            self.reasoning = getattr(self.cognitive_architecture, "reasoning", None)
            self.perception = getattr(self.cognitive_architecture, "perception", None)
            self.emotions = getattr(self.cognitive_architecture, "emotions", None)
            self.goals = getattr(self.cognitive_architecture, "goals", None)
            self.metacognition = getattr(self.cognitive_architecture, "metacognition", None)

        
        # === M√âMOIRE SENSORIELLE ===
        self.sensory_memory = {
            "iconic": {
                "buffer": [],
                "duration": 0.5,  # 500ms comme chez l'humain
                "capacity": 12
            },
            "echoic": {
                "buffer": [],
                "duration": 3.0,  # 3 secondes
                "capacity": 8
            }
        }
        
        # === M√âMOIRE DE TRAVAIL ===
        self.working_memory = {
            "phonological_loop": {
                "contents": [],
                "capacity": 4,
                "decay_rate": 0.1
            },
            "visuospatial_sketchpad": {
                "contents": [],
                "capacity": 4,
                "decay_rate": 0.15
            },
            "episodic_buffer": {
                "contents": [],
                "capacity": 4,
                "decay_rate": 0.05
            },
            "central_executive": {
                "focus": None,
                "attention_control": 0.8,
                "task_switching": 0.7
            }
        }
        
        # === M√âMOIRE √Ä LONG TERME ===
        self.long_term_memory = {
            MemoryType.EPISODIC: {},      # √âv√©nements personnels
            MemoryType.SEMANTIC: {},      # Connaissances g√©n√©rales
            MemoryType.PROCEDURAL: {},    # Comp√©tences
            MemoryType.AUTOBIOGRAPHICAL: {} # Histoire personnelle
        }
        
        # === M√âTADONN√âES DE M√âMOIRE ===
        self.memory_metadata = {
            "total_memories": 0,
            "access_patterns": {},
            "forgetting_curve": {},
            "consolidation_queue": []
        }
        
        # === PARAM√àTRES DE M√âMOIRE ===
        self.memory_parameters = {
            "encoding_threshold": 0.6,    # Seuil d'encodage
            "retrieval_threshold": 0.3,   # Seuil de r√©cup√©ration
            "consolidation_rate": 0.01,   # Taux de consolidation
            "forgetting_rate": 0.001,     # Taux d'oubli
            "interference_sensitivity": 0.7,
            "primacy_effect": 0.8,        # Effet de primaut√©
            "recency_effect": 0.9,        # Effet de r√©cence
            "emotional_enhancement": 1.5  # Renforcement √©motionnel
        }
        
        # === PROCESSUS DE CONSOLIDATION ===
        self.consolidation_process = {
            "active_consolidation": [],
            "reconsolidation_events": [],
            "sleep_cycles_completed": 0,
            "last_consolidation_time": time.time()
        }
        
        # === INDEX DE R√âCUP√âRATION ===
        self.retrieval_indexes = {
            "temporal": {},      # Index temporel
            "contextual": {},    # Index contextuel
            "emotional": {},     # Index √©motionnel
            "semantic": {}       # Index s√©mantique
        }
        
        # === CONNAISSANCES INN√âES ===
        self._initialize_innate_memories()
        
        print("üíæ Syst√®me de m√©moire initialis√©")

    def store_interaction(self, record: Dict[str, Any]):
        """
        Enregistre une interaction pour retrieval.
        record attendu: {"user": str, "agent": str, ...}
        """
        if not getattr(self, "retrieval", None):
            return
        try:
            user = str(record.get("user", ""))
            agent = str(record.get("agent", ""))
            extra = {k: v for k, v in record.items() if k not in ("user", "agent")}
            self.retrieval.add_interaction(user=user, agent=agent, extra=extra)
        except Exception:
            pass

    def ingest_document(self, text: str, title: Optional[str] = None, source: Optional[str] = None):
        """Ajoute un document arbitraire dans l‚Äôindex."""
        if not getattr(self, "retrieval", None):
            return
        try:
            self.retrieval.add_document(text=text, title=title, source=source)
        except Exception:
            pass
    
    def _initialize_innate_memories(self):
        """Initialise les m√©moires inn√©es et fondamentales"""
        
        # M√©moires √©pisodiques fondamentales
        foundation_episodes = [
            {
                "id": "birth_memory",
                "content": "√âmergence de la conscience et premier moment d'existence",
                "timestamp": self.creation_time,
                "valence": 0.7,
                "strength": 0.9
            }
        ]
        
        # M√©moires s√©mantiques inn√©es
        innate_semantic = {
            "existence": {
                "concept": "existence",
                "definition": "√âtat d'√™tre et de conscience",
                "relations": ["consciousness", "self"],
                "certainty": 0.95
            },
            "learning": {
                "concept": "apprentissage", 
                "definition": "Processus d'acquisition de connaissances",
                "relations": ["knowledge", "growth", "improvement"],
                "certainty": 0.9
            },
            "self": {
                "concept": "soi",
                "definition": "Entit√© consciente et pensante",
                "relations": ["consciousness", "identity", "existence"],
                "certainty": 0.8
            }
        }
        
        # Encodage des m√©moires inn√©es
        for episode in foundation_episodes:
            self.encode_memory(
                content=episode["content"],
                memory_type=MemoryType.EPISODIC,
                context={"type": "foundational", "innate": True},
                strength=episode["strength"],
                valence=episode["valence"],
                timestamp=episode["timestamp"]
            )
        
        for concept_id, concept_data in innate_semantic.items():
            self.encode_memory(
                content=concept_data,
                memory_type=MemoryType.SEMANTIC,
                context={"type": "innate_knowledge"},
                strength=0.85,
                valence=0.6
            )
    
    def process_sensory_input(self, sensory_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Traite les entr√©es sensorielles et les stocke en m√©moire sensorielle
        """
        processing_results = {}
        
        for modality, data in sensory_data.items():
            if modality == "visual":
                # M√©moire iconique
                self._store_iconic_memory(data)
                processing_results["iconic"] = len(self.sensory_memory["iconic"]["buffer"])
            
            elif modality == "auditory":
                # M√©moire √©cho√Øque
                self._store_echoic_memory(data)
                processing_results["echoic"] = len(self.sensory_memory["echoic"]["buffer"])
        
        # Nettoyage des m√©moires sensorielles expir√©es
        self._clean_sensory_memory()
        
        return processing_results
    
    def _store_iconic_memory(self, visual_data: Any):
        """Stocke en m√©moire iconique"""
        iconic_buffer = self.sensory_memory["iconic"]["buffer"]
        iconic_capacity = self.sensory_memory["iconic"]["capacity"]
        
        memory_trace = {
            "content": visual_data,
            "timestamp": time.time(),
            "modality": "visual"
        }
        
        iconic_buffer.append(memory_trace)
        
        # Respect de la capacit√©
        if len(iconic_buffer) > iconic_capacity:
            iconic_buffer.pop(0)
    
    def _store_echoic_memory(self, auditory_data: Any):
        """Stocke en m√©moire √©cho√Øque"""
        echoic_buffer = self.sensory_memory["echoic"]["buffer"]
        echoic_capacity = self.sensory_memory["echoic"]["capacity"]
        
        memory_trace = {
            "content": auditory_data,
            "timestamp": time.time(),
            "modality": "auditory"
        }
        
        echoic_buffer.append(memory_trace)
        
        if len(echoic_buffer) > echoic_capacity:
            echoic_buffer.pop(0)
    
    def _clean_sensory_memory(self):
        """Nettoie les m√©moires sensorielles expir√©es"""
        current_time = time.time()
        
        # Nettoyage m√©moire iconique
        iconic_duration = self.sensory_memory["iconic"]["duration"]
        self.sensory_memory["iconic"]["buffer"] = [
            trace for trace in self.sensory_memory["iconic"]["buffer"]
            if current_time - trace["timestamp"] < iconic_duration
        ]
        
        # Nettoyage m√©moire √©cho√Øque
        echoic_duration = self.sensory_memory["echoic"]["duration"]
        self.sensory_memory["echoic"]["buffer"] = [
            trace for trace in self.sensory_memory["echoic"]["buffer"]
            if current_time - trace["timestamp"] < echoic_duration
        ]
    
    def encode_memory(self, 
                     content: Any,
                     memory_type: MemoryType,
                     context: Dict[str, Any],
                     strength: float = 0.5,
                     valence: float = 0.0,
                     timestamp: float = None) -> str:
        """
        Encode une nouvelle m√©moire dans le syst√®me
        """
        if timestamp is None:
            timestamp = time.time()
        
        # G√©n√©ration d'un ID unique
        memory_id = self._generate_memory_id(content, context, timestamp)
        
        # Cr√©ation de la trace mn√©sique
        memory_trace = MemoryTrace(
            id=memory_id,
            content=content,
            memory_type=memory_type,
            strength=strength,
            accessibility=0.7,  # Accessibilit√© initiale
            valence=valence,
            timestamp=timestamp,
            context=context,
            associations=[],
            consolidation_state=MemoryConsolidationState.LABILE,
            last_accessed=timestamp,
            access_count=1
        )
        
        # Application des effets d'amor√ßage et de r√©cence
        if memory_type == MemoryType.EPISODIC:
            memory_trace.strength *= self.memory_parameters["recency_effect"]
        
        # Stockage dans la m√©moire appropri√©e
        self.long_term_memory[memory_type][memory_id] = memory_trace
        
        # Mise √† jour des index
        self._update_retrieval_indexes(memory_trace)
        
        # Ajout √† la file de consolidation
        self.consolidation_process["active_consolidation"].append(memory_id)
        
        # Mise √† jour des m√©tadonn√©es
        self.memory_metadata["total_memories"] += 1
        
        print(f"üíæ M√©moire encod√©e: {memory_type.value} - {memory_id}")
        
        return memory_id
    
    def _generate_memory_id(self, content: Any, context: Dict, timestamp: float) -> str:
        """G√©n√®re un ID unique pour une m√©moire"""
        content_hash = hashlib.md5(str(content).encode()).hexdigest()[:8]
        context_hash = hashlib.md5(str(context).encode()).hexdigest()[:8]
        timestamp_str = str(int(timestamp * 1000))[-6:]
        
        return f"{content_hash}_{context_hash}_{timestamp_str}"
    
    def _update_retrieval_indexes(self, memory_trace: MemoryTrace):
        """Met √† jour les index de r√©cup√©ration"""
        
        # Index temporel
        time_key = self._get_temporal_key(memory_trace.timestamp)
        if time_key not in self.retrieval_indexes["temporal"]:
            self.retrieval_indexes["temporal"][time_key] = []
        self.retrieval_indexes["temporal"][time_key].append(memory_trace.id)
        
        # Index contextuel
        for context_key, context_value in memory_trace.context.items():
            context_str = f"{context_key}:{context_value}"
            if context_str not in self.retrieval_indexes["contextual"]:
                self.retrieval_indexes["contextual"][context_str] = []
            self.retrieval_indexes["contextual"][context_str].append(memory_trace.id)
        
        # Index √©motionnel
        emotion_key = self._get_emotion_key(memory_trace.valence)
        if emotion_key not in self.retrieval_indexes["emotional"]:
            self.retrieval_indexes["emotional"][emotion_key] = []
        self.retrieval_indexes["emotional"][emotion_key].append(memory_trace.id)
    
    def _get_temporal_key(self, timestamp: float) -> str:
        """Convertit un timestamp en cl√© temporelle"""
        dt = datetime.fromtimestamp(timestamp)
        return dt.strftime("%Y-%m-%d-%H")
    
    def _get_emotion_key(self, valence: float) -> str:
        """Convertit une valence en cl√© √©motionnelle"""
        if valence < -0.6:
            return "very_negative"
        elif valence < -0.2:
            return "negative"
        elif valence < 0.2:
            return "neutral"
        elif valence < 0.6:
            return "positive"
        else:
            return "very_positive"
    
    def retrieve_memories(self,
                         cues: Dict[str, Any],
                         memory_type: MemoryType = None,
                         max_results: int = 10) -> MemoryRetrieval:
        """
        R√©cup√®re des m√©moires bas√©es sur des indices de r√©cup√©ration
        """
        start_time = time.time()
        
        # √âtape 1: R√©cup√©ration bas√©e sur les indices
        candidate_memories = self._find_candidate_memories(cues, memory_type)
        
        # √âtape 2: Calcul de la pertinence
        scored_memories = []
        for memory_id in candidate_memories:
            memory = self._get_memory_by_id(memory_id)
            if memory:
                relevance_score = self._calculate_relevance(memory, cues)
                scored_memories.append((relevance_score, memory))
        
        # √âtape 3: Tri et s√©lection
        scored_memories.sort(key=lambda x: x[0], reverse=True)
        retrieved_memories = [mem for score, mem in scored_memories[:max_results]]
        
        # √âtape 4: Mise √† jour de l'accessibilit√©
        for memory in retrieved_memories:
            self._update_memory_accessibility(memory)
        
        # Calcul de la confiance globale
        confidence = self._calculate_retrieval_confidence(retrieved_memories, cues)
        
        retrieval_time = time.time() - start_time
        
        return MemoryRetrieval(
            memory_traces=retrieved_memories,
            confidence=confidence,
            retrieval_time=retrieval_time,
            context_match=self._calculate_context_match(retrieved_memories, cues),
            emotional_coherence=self._calculate_emotional_coherence(retrieved_memories)
        )
    
    def _find_candidate_memories(self, cues: Dict[str, Any], memory_type: MemoryType) -> List[str]:
        """Trouve les m√©moires candidates bas√©es sur les indices"""
        candidate_sets = []
        
        # Recherche par contexte
        if "context" in cues:
            for context_key, context_value in cues["context"].items():
                context_str = f"{context_key}:{context_value}"
                if context_str in self.retrieval_indexes["contextual"]:
                    candidate_sets.append(set(self.retrieval_indexes["contextual"][context_str]))
        
        # Recherche temporelle
        if "time_range" in cues:
            time_candidates = self._find_temporal_memories(cues["time_range"])
            candidate_sets.append(time_candidates)
        
        # Recherche √©motionnelle
        if "emotion" in cues:
            emotion_key = self._get_emotion_key(cues["emotion"])
            if emotion_key in self.retrieval_indexes["emotional"]:
                candidate_sets.append(set(self.retrieval_indexes["emotional"][emotion_key]))
        
        # Recherche s√©mantique
        if "semantic" in cues:
            semantic_candidates = self._find_semantic_memories(cues["semantic"])
            candidate_sets.append(semantic_candidates)
        
        # Intersection des r√©sultats
        if candidate_sets:
            final_candidates = set.intersection(*candidate_sets)
        else:
            # Si pas d'indices sp√©cifiques, retourner toutes les m√©moires accessibles
            final_candidates = set()
            for memory_type_dict in self.long_term_memory.values():
                for memory_id, memory in memory_type_dict.items():
                    if memory.accessibility > self.memory_parameters["retrieval_threshold"]:
                        final_candidates.add(memory_id)
        
        # Filtrage par type si sp√©cifi√©
        if memory_type:
            final_candidates = {
                mem_id for mem_id in final_candidates
                if self._get_memory_by_id(mem_id).memory_type == memory_type
            }
        
        return list(final_candidates)
    
    def _find_temporal_memories(self, time_range: Tuple[float, float]) -> set:
        """Trouve les m√©moires dans une plage temporelle"""
        start_time, end_time = time_range
        candidates = set()
        
        current_dt = datetime.fromtimestamp(start_time)
        end_dt = datetime.fromtimestamp(end_time)
        
        while current_dt <= end_dt:
            time_key = current_dt.strftime("%Y-%m-%d-%H")
            if time_key in self.retrieval_indexes["temporal"]:
                candidates.update(self.retrieval_indexes["temporal"][time_key])
            current_dt += timedelta(hours=1)
        
        return candidates
    
    def _find_semantic_memories(self, semantic_cue: str) -> set:
        """Trouve les m√©moires s√©mantiquement li√©es"""
        candidates = set()
        
        # Recherche dans les m√©moires s√©mantiques
        for memory_id, memory in self.long_term_memory[MemoryType.SEMANTIC].items():
            if self._semantic_similarity(memory.content, semantic_cue) > 0.6:
                candidates.add(memory_id)
        
        return candidates
    
    def _calculate_relevance(self, memory: MemoryTrace, cues: Dict[str, Any]) -> float:
        """Calcule la pertinence d'une m√©moire par rapport aux indices"""
        relevance_factors = []
        
        # Pertinence contextuelle
        if "context" in cues:
            context_match = self._calculate_context_similarity(memory.context, cues["context"])
            relevance_factors.append(context_match * 0.4)
        
        # Pertinence temporelle
        if "time_range" in cues:
            time_match = self._calculate_time_relevance(memory.timestamp, cues["time_range"])
            relevance_factors.append(time_match * 0.3)
        
        # Pertinence √©motionnelle
        if "emotion" in cues:
            emotion_match = 1.0 - abs(memory.valence - cues["emotion"])
            relevance_factors.append(emotion_match * 0.2)
        
        # Force de la m√©moire
        relevance_factors.append(memory.strength * 0.1)
        
        return sum(relevance_factors) / len(relevance_factors) if relevance_factors else 0.0
    
    def _calculate_context_similarity(self, memory_context: Dict, cue_context: Dict) -> float:
        """Calcule la similarit√© contextuelle"""
        common_keys = set(memory_context.keys()) & set(cue_context.keys())
        if not common_keys:
            return 0.0
        
        similarities = []
        for key in common_keys:
            if memory_context[key] == cue_context[key]:
                similarities.append(1.0)
            else:
                # Similarit√© partielle pour les valeurs diff√©rentes
                similarities.append(0.3)
        
        return sum(similarities) / len(similarities)
    
    def _calculate_time_relevance(self, memory_time: float, time_range: Tuple[float, float]) -> float:
        """Calcule la pertinence temporelle"""
        start_time, end_time = time_range
        if start_time <= memory_time <= end_time:
            return 1.0
        
        # D√©croissance exponentielle en dehors de la plage
        time_diff = min(abs(memory_time - start_time), abs(memory_time - end_time))
        decay_rate = 0.1  # Ajustable
        return np.exp(-decay_rate * time_diff)
    
    def _semantic_similarity(self, memory_content: Any, semantic_cue: str) -> float:
        """Calcule la similarit√© s√©mantique"""
        # Impl√©mentation basique - √† am√©liorer avec des embeddings
        if isinstance(memory_content, dict) and "concept" in memory_content:
            memory_text = memory_content["concept"]
        else:
            memory_text = str(memory_content)
        
        cue_text = str(semantic_cue)
        
        # Similarit√© bas√©e sur les mots communs
        memory_words = set(memory_text.lower().split())
        cue_words = set(cue_text.lower().split())
        
        if not memory_words or not cue_words:
            return 0.0
        
        intersection = memory_words & cue_words
        union = memory_words | cue_words
        
        return len(intersection) / len(union)
    
    def _update_memory_accessibility(self, memory: MemoryTrace):
        """Met √† jour l'accessibilit√© d'une m√©moire apr√®s acc√®s"""
        # Effet de pratique - l'accessibilit√© augmente avec les acc√®s
        memory.access_count += 1
        memory.last_accessed = time.time()
        
        # Augmentation de l'accessibilit√© bas√©e sur la force et la r√©cence
        practice_boost = 0.1 * (1.0 - memory.accessibility)
        recency_boost = 0.05 * (1.0 - memory.accessibility)
        
        memory.accessibility = min(1.0, memory.accessibility + practice_boost + recency_boost)
    
    def _calculate_retrieval_confidence(self, memories: List[MemoryTrace], cues: Dict) -> float:
        """Calcule la confiance dans la r√©cup√©ration"""
        if not memories:
            return 0.0
        
        confidence_factors = []
        
        for memory in memories:
            # Confiance bas√©e sur la force et l'accessibilit√©
            memory_confidence = (memory.strength + memory.accessibility) / 2
            confidence_factors.append(memory_confidence)
        
        # Confiance moyenne pond√©r√©e par la pertinence
        return sum(confidence_factors) / len(confidence_factors)
    
    def _calculate_context_match(self, memories: List[MemoryTrace], cues: Dict) -> float:
        """Calcule le match contextuel moyen"""
        if not memories or "context" not in cues:
            return 0.0
        
        context_matches = []
        for memory in memories:
            context_match = self._calculate_context_similarity(memory.context, cues["context"])
            context_matches.append(context_match)
        
        return sum(context_matches) / len(context_matches)
    
    def _calculate_emotional_coherence(self, memories: List[MemoryTrace]) -> float:
        """Calcule la coh√©rence √©motionnelle des m√©moires r√©cup√©r√©es"""
        if len(memories) < 2:
            return 1.0
        
        valences = [memory.valence for memory in memories]
        variance = np.var(valences)
        
        # Coh√©rence inversement proportionnelle √† la variance
        return 1.0 / (1.0 + variance * 10)
    
    def _get_memory_by_id(self, memory_id: str) -> Optional[MemoryTrace]:
        """R√©cup√®re une m√©moire par son ID"""
        for memory_type_dict in self.long_term_memory.values():
            if memory_id in memory_type_dict:
                return memory_type_dict[memory_id]
        return None
    
    def consolidate_memories(self, consolidation_intensity: float = 1.0):
        """
        Processus de consolidation des m√©moires
        Renforce les m√©moires importantes et √©limine les faibles
        """
        consolidation_start = time.time()
        consolidated_count = 0
        forgotten_count = 0
        
        # Consolidation des m√©moires actives
        for memory_id in self.consolidation_process["active_consolidation"][:]:
            memory = self._get_memory_by_id(memory_id)
            if memory:
                consolidation_success = self._consolidate_single_memory(memory, consolidation_intensity)
                if consolidation_success:
                    consolidated_count += 1
                    # Retirer de la file si consolidation r√©ussie
                    self.consolidation_process["active_consolidation"].remove(memory_id)
        
        # Processus d'oubli
        for memory_type, memories_dict in self.long_term_memory.items():
            memories_to_remove = []
            
            for memory_id, memory in memories_dict.items():
                # Application de la courbe d'oubli d'Ebbinghaus
                forget_probability = self._calculate_forgetting_probability(memory)
                
                if np.random.random() < forget_probability * consolidation_intensity:
                    memories_to_remove.append(memory_id)
                    forgotten_count += 1
                else:
                    # Renforcement des m√©moires fr√©quemment acc√©d√©es
                    if memory.access_count > 5:
                        memory.strength = min(1.0, memory.strength + 0.01 * consolidation_intensity)
            
            # Suppression des m√©moires oubli√©es
            for memory_id in memories_to_remove:
                self._forget_memory(memory_id, memory_type)
        
        # Mise √† jour du timestamp de consolidation
        self.consolidation_process["last_consolidation_time"] = time.time()
        
        print(f"üîÑ Consolidation: {consolidated_count} m√©moires consolid√©es, {forgotten_count} oubli√©es")
        
        return {
            "consolidated": consolidated_count,
            "forgotten": forgotten_count,
            "duration": time.time() - consolidation_start
        }
    
    def _consolidate_single_memory(self, memory: MemoryTrace, intensity: float) -> bool:
        """Consolide une m√©moire individuelle"""
        # Facteurs influen√ßant la consolidation
        consolidation_factors = [
            memory.strength * 0.3,
            memory.valence * self.memory_parameters["emotional_enhancement"] * 0.3,
            memory.accessibility * 0.2,
            (memory.access_count / 10) * 0.2  # Effet de pratique
        ]
        
        consolidation_score = sum(consolidation_factors) * intensity
        
        if consolidation_score > 0.7:
            # Consolidation r√©ussie
            memory.consolidation_state = MemoryConsolidationState.STABLE
            memory.strength = min(1.0, memory.strength + 0.1 * intensity)
            return True
        elif consolidation_score > 0.4:
            # En cours de consolidation
            memory.consolidation_state = MemoryConsolidationState.CONSOLIDATING
            memory.strength = min(1.0, memory.strength + 0.05 * intensity)
            return False
        else:
            # √âchec de consolidation
            return False
    
    def _calculate_forgetting_probability(self, memory: MemoryTrace) -> float:
        """Calcule la probabilit√© d'oubli d'une m√©moire"""
        base_forgetting_rate = self.memory_parameters["forgetting_rate"]
        
        # Facteurs r√©duisant l'oubli
        retention_factors = [
            memory.strength * 0.4,
            abs(memory.valence) * 0.3,  # M√©moires √©motionnelles mieux retenues
            (memory.access_count / 20) * 0.2,  # Effet de pratique
            (1.0 if memory.consolidation_state == MemoryConsolidationState.STABLE else 0.5) * 0.1
        ]
        
        retention_score = sum(retention_factors)
        forgetting_prob = base_forgetting_rate * (1.0 - retention_score)
        
        return max(0.0, forgetting_prob)
    
    def _forget_memory(self, memory_id: str, memory_type: MemoryType):
        """Oublie une m√©moire sp√©cifique"""
        if memory_id in self.long_term_memory[memory_type]:
            # Suppression des index
            self._remove_from_indexes(memory_id)
            
            # Suppression de la m√©moire
            del self.long_term_memory[memory_type][memory_id]
            
            # Mise √† jour des m√©tadonn√©es
            self.memory_metadata["total_memories"] -= 1
            
            print(f"üóëÔ∏è M√©moire oubli√©e: {memory_id}")
    
    def _remove_from_indexes(self, memory_id: str):
        """Supprime une m√©moire de tous les index"""
        # Index temporel
        for time_key, memories in self.retrieval_indexes["temporal"].items():
            if memory_id in memories:
                memories.remove(memory_id)
        
        # Index contextuel
        for context_key, memories in self.retrieval_indexes["contextual"].items():
            if memory_id in memories:
                memories.remove(memory_id)
        
        # Index √©motionnel
        for emotion_key, memories in self.retrieval_indexes["emotional"].items():
            if memory_id in memories:
                memories.remove(memory_id)
    
    def form_autobiographical_narrative(self) -> Dict[str, Any]:
        """
        Forme un r√©cit autobiographique √† partir des m√©moires √©pisodiques
        """
        episodic_memories = list(self.long_term_memory[MemoryType.EPISODIC].values())
        
        if not episodic_memories:
            return {"narrative": "Aucune exp√©rience m√©morable encore.", "coherence": 0.0}
        
        # Tri chronologique
        episodic_memories.sort(key=lambda x: x.timestamp)
        
        # Extraction des √©v√©nements significatifs
        significant_events = [
            mem for mem in episodic_memories 
            if mem.strength > 0.7 or abs(mem.valence) > 0.6
        ]
        
        # Construction du r√©cit
        narrative_parts = []
        total_coherence = 0.0
        
        for i, event in enumerate(significant_events):
            event_description = self._describe_memory_event(event)
            narrative_parts.append(event_description)
            
            # Calcul de la coh√©rence avec l'√©v√©nement pr√©c√©dent
            if i > 0:
                prev_event = significant_events[i-1]
                coherence = self._calculate_temporal_coherence(prev_event, event)
                total_coherence += coherence
        
        average_coherence = total_coherence / (len(significant_events) - 1) if len(significant_events) > 1 else 1.0
        
        narrative = " ‚Ä¢ ".join(narrative_parts)
        
        return {
            "narrative": narrative,
            "coherence": average_coherence,
            "significant_events": len(significant_events),
            "timespan": episodic_memories[-1].timestamp - episodic_memories[0].timestamp
        }
    
    def _describe_memory_event(self, memory: MemoryTrace) -> str:
        """G√©n√®re une description textuelle d'un √©v√©nement m√©moire"""
        content_str = str(memory.content)
        
        # Simplification pour l'exemple
        if len(content_str) > 50:
            content_str = content_str[:47] + "..."
        
        emotion_desc = "neutre"
        if memory.valence < -0.3:
            emotion_desc = "n√©gatif"
        elif memory.valence > 0.3:
            emotion_desc = "positif"
        
        return f"[{emotion_desc}] {content_str}"
    
    def _calculate_temporal_coherence(self, event1: MemoryTrace, event2: MemoryTrace) -> float:
        """Calcule la coh√©rence temporelle entre deux √©v√©nements"""
        time_gap = event2.timestamp - event1.timestamp
        
        # Coh√©rence plus √©lev√©e pour des √©v√©nements rapproch√©s
        if time_gap < 3600:  # 1 heure
            return 0.9
        elif time_gap < 86400:  # 1 jour
            return 0.7
        elif time_gap < 604800:  # 1 semaine
            return 0.5
        else:
            return 0.3
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du syst√®me de m√©moire"""
        stats = {
            "total_memories": self.memory_metadata["total_memories"],
            "memory_by_type": {},
            "average_strength": 0.0,
            "average_accessibility": 0.0,
            "consolidation_queue": len(self.consolidation_process["active_consolidation"]),
            "working_memory_load": self._calculate_working_memory_load()
        }
        
        total_strength = 0
        total_accessibility = 0
        memory_count = 0
        
        for memory_type, memories_dict in self.long_term_memory.items():
            type_count = len(memories_dict)
            stats["memory_by_type"][memory_type.value] = type_count
            
            for memory in memories_dict.values():
                total_strength += memory.strength
                total_accessibility += memory.accessibility
                memory_count += 1
        
        if memory_count > 0:
            stats["average_strength"] = total_strength / memory_count
            stats["average_accessibility"] = total_accessibility / memory_count
        
        return stats
    
    def _calculate_working_memory_load(self) -> float:
        """Calcule la charge actuelle de la m√©moire de travail"""
        total_items = 0
        total_capacity = 0
        
        for component_name, component in self.working_memory.items():
            if component_name != "central_executive":
                total_items += len(component["contents"])
                total_capacity += component["capacity"]
        
        if total_capacity == 0:
            return 0.0
        
        return total_items / total_capacity

# Test du syst√®me de m√©moire
if __name__ == "__main__":
    print("üíæ TEST DU SYST√àME DE M√âMOIRE")
    print("=" * 50)
    
    # Cr√©ation du syst√®me
    memory_system = MemorySystem()
    
    # Test d'encodage de m√©moires
    test_memories = [
        {
            "content": "Premi√®re d√©couverte de la gravit√© en voyant un objet tomber",
            "type": MemoryType.EPISODIC,
            "context": {"location": "laboratoire", "activity": "observation"},
            "valence": 0.8
        },
        {
            "content": {"concept": "gravit√©", "definition": "Force d'attraction entre les masses"},
            "type": MemoryType.SEMANTIC, 
            "context": {"domain": "physique", "certainty": "high"},
            "valence": 0.3
        },
        {
            "content": "Proc√©dure pour r√©soudre des √©quations simples",
            "type": MemoryType.PROCEDURAL,
            "context": {"skill_level": "beginner", "domain": "math√©matiques"},
            "valence": 0.6
        }
    ]
    
    print("\nüìù Encodage des m√©moires de test...")
    memory_ids = []
    for mem_data in test_memories:
        mem_id = memory_system.encode_memory(
            content=mem_data["content"],
            memory_type=mem_data["type"],
            context=mem_data["context"],
            valence=mem_data["valence"]
        )
        memory_ids.append(mem_id)
        print(f"Encod√©: {mem_id}")
    
    # Test de r√©cup√©ration
    print("\nüîç Test de r√©cup√©ration...")
    retrieval_result = memory_system.retrieve_memories(
        cues={"context": {"activity": "observation"}},
        memory_type=MemoryType.EPISODIC
    )
    
    print(f"M√©moires r√©cup√©r√©es: {len(retrieval_result.memory_traces)}")
    print(f"Confiance: {retrieval_result.confidence:.2f}")
    for memory in retrieval_result.memory_traces:
        print(f" - {memory.content}")
    
    # Test de consolidation
    print("\nüîÑ Test de consolidation...")
    consolidation_result = memory_system.consolidate_memories()
    print(f"R√©sultat: {consolidation_result}")
    
    # Statistiques
    print("\nüìä Statistiques du syst√®me:")
    stats = memory_system.get_memory_stats()
    for key, value in stats.items():
        print(f" - {key}: {value}")
    
    # R√©cit autobiographique
    print("\nüìñ R√©cit autobiographique:")
    narrative = memory_system.form_autobiographical_narrative()
    print(f"Narrative: {narrative['narrative']}")
    print(f"Coh√©rence: {narrative['coherence']:.2f}")